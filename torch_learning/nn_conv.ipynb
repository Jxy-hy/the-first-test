{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trian_dataset = torchvision.datasets.CIFAR10(\"./dataset\",\n",
    "                                             train=False,\n",
    "                                             transform = torchvision.transforms.ToTensor(),\n",
    "                                             download=True)\n",
    "dataloader = DataLoader(trian_dataset,batch_size=64,shuffle=True,drop_last=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<P style = \"color : blue;font-size: 19px;\">\n",
    "<b>F.conv2以下参数:</b><br>\n",
    "input输入必须为tensor类型而且必须满足有size，channel，width，height四个属性<br>\n",
    "output输出和输入有一样的数据类型<br>\n",
    "kernel_size必须和input是一样的数据类型<br>\n",
    "stride步长，padding填充，默认填充为零<br>\n",
    "bias常设为true给最后的结果加一个常数，dilation分组卷积一般为默认值<br>\n",
    "<b>nn.conv2以下参数:<br></b>\n",
    "in_channel为输入的通道数，out_channels为输出的通道数，kernel_size卷积核大小其他参数和以上一样<br>\n",
    "<i style = \"color : green;\">需要注意的是若输出通道比输入通道数多就代表学习了多种特征，比如一个三通道图片输入，十二通道的图片输出就代表学习了四种特征<br>\n",
    "<i style = \"color : green;\">卷积核中的值就是模型的参数，经过反向传播得到<br>\n",
    "</p>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "class eazy_conv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(eazy_conv, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=0)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"./tensorboard/nn_conv\")\n",
    "step = 0\n",
    "Eazy_conv = eazy_conv()\n",
    "for data in dataloader:\n",
    "    imgs , target = data\n",
    "    output = Eazy_conv(imgs)\n",
    "    writer.add_images(\"input\",imgs,step)\n",
    "    output = torch.reshape(output,(-1,3,30,30))\n",
    "    writer.add_images(\"output\",output,step)\n",
    "    step += 1\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

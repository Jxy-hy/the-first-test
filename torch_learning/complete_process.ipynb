{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.optim\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "outputs": [],
   "source": [
    "laring_rate = 0.0001\n",
    "batch_size = 256\n",
    "epoch = 70\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(\"./dataset\",transform=torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomRotation((-90,90)),\n",
    "    torchvision.transforms.ToTensor()]),train=True,download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(\"./dataset\",transform=torchvision.transforms.ToTensor(),train=False,download=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集的长度为：50000\n",
      "测试集的长度为：10000\n"
     ]
    }
   ],
   "source": [
    "print(\"训练集的长度为：{}\".format(len(train_dataset)))\n",
    "print(\"测试集的长度为：{}\".format(len(test_dataset)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,batch_size,shuffle=True,drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset,batch_size,shuffle=True,drop_last=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "CIFAR10网络结构改进详解\n",
    "我将详细解释每个改进层的添加目的和意义，帮助您理解这些修改如何提升模型性能：\n",
    "1. Batch Normalization (批归一化层)\n",
    "​​添加位置​​：在每个卷积层之后、激活函数之前\n",
    "​​目的和意义​​：\n",
    "​​稳定训练过程​​：通过标准化每层的输入分布，减少内部协变量偏移(Internal Covariate Shift)\n",
    "​​允许使用更高学习率​​：BN使网络对学习率的选择更鲁棒\n",
    "​​减少对初始化的依赖​​：降低网络对权重初始化的敏感性\n",
    "​​轻微的正则化效果​​：通过每个batch的统计量引入噪声\n",
    "​​加速收敛​​：实验表明BN可以使训练速度提高10倍以上\n",
    "​​为什么需要​​：在原始结构中，深层网络容易因输入分布变化而训练困难，BN解决了这个问题\n",
    "2. ReLU激活函数\n",
    "​​添加位置​​：在每个卷积层和全连接层之后\n",
    "​​目的和意义​​：\n",
    "​​引入非线性​​：使网络能够学习复杂模式（原始结构缺少激活函数，相当于线性变换）\n",
    "​​解决梯度消失​​：相比Sigmoid/Tanh，ReLU在正区间梯度恒为1\n",
    "​​稀疏激活​​：只有部分神经元被激活，提高计算效率\n",
    "​​加速收敛​​：线性特性使梯度计算更简单高效\n",
    "​​为什么需要​​：原始结构没有激活函数，网络只能表达线性关系，无法学习复杂特征\n",
    "3. Dropout层\n",
    "​​添加位置​​：在全连接层之间\n",
    "​​目的和意义​​：\n",
    "​​防止过拟合​​：随机丢弃部分神经元(50%和30%)，强制网络学习冗余表示\n",
    "​​模型集成效果​​：每次前向传播相当于不同的子网络\n",
    "​​减少神经元共适应​​：防止神经元过度依赖特定特征\n",
    "​​提高泛化能力​​：在CIFAR10这种小数据集上尤为重要\n",
    "​​为什么需要​​：原始结构没有正则化措施，容易在训练集上过拟合\n",
    "4. 改进的全连接层结构\n",
    "​​原始结构​​：64×4×4(1024维) → 64维 → 10维\n",
    "​​改进结构​​：1024维 → 256维 → 128维 → 10维\n",
    "​​目的和意义​​：\n",
    "​​平缓降维​​：避免信息瓶颈，保留更多特征信息\n",
    "​​增加模型容量​​：256和128维的中间层提供更多学习空间\n",
    "​​分层特征提取​​：允许网络学习更抽象的高级特征\n",
    "​​减少信息损失​​：1024→64的骤降可能导致重要特征丢失\n",
    "​​为什么需要​​：原始结构降维过于激进，可能丢失重要分类信息\n",
    "5. 分离特征提取和分类器\n",
    "​​结构变化​​：将网络分为features和classifier两个模块\n",
    "​​目的和意义​​：\n",
    "​​模块化设计​​：提高代码可读性和可维护性\n",
    "​​便于迁移学习​​：可单独替换分类器用于其他任务\n",
    "​​清晰职责划分​​：卷积部分专注特征提取，全连接部分专注分类\n",
    "​​调试更方便​​：可独立检查各模块输出\n",
    "​​为什么需要​​：原始单一序列结构不利于扩展和调试"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "outputs": [],
   "source": [
    "#实验表明明显拟合效果以及泛化能力不如下面改进过的网络\n",
    "# class CIFAR10(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CIFAR10, self).__init__()\n",
    "#         self.module = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels=3,out_channels=32,kernel_size=5,stride=1,padding=2),\n",
    "#             nn.MaxPool2d(kernel_size=2),\n",
    "#             nn.Conv2d(in_channels=32,out_channels=32,kernel_size=5,stride=1,padding=2),\n",
    "#             nn.MaxPool2d(kernel_size=2),\n",
    "#             nn.Conv2d(in_channels=32,out_channels=64,kernel_size=5,stride=1,padding=2),\n",
    "#             nn.MaxPool2d(kernel_size=2),\n",
    "#             nn.Flatten(),\n",
    "#             nn.Linear(64*4*4,128),\n",
    "#             nn.Linear(128,64),\n",
    "#             nn.Linear(64,10)\n",
    "#         )\n",
    "#\n",
    "#     def forward(self,x):\n",
    "#         x = self.module(x)\n",
    "#         return x\n",
    "# 修改后的网络\n",
    "class CIFAR10(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CIFAR10, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # 输入: 3x32x32\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),#\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),  # 输出: 32x16x16\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),  # 输出: 32x8x8\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),  # 输出: 64x4x4\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 4 * 4, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"./tensorboard/complate\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [],
   "source": [
    "#创建网络模型\n",
    "cifar = CIFAR10()\n",
    "cifar.load_state_dict(torch.load(\"best_cifar10.pth\"))#是否在以前的基础上再进行训练\n",
    "cifar = cifar.to(device)\n",
    "# if torch.cuda.is_available():\n",
    "#     cifar = cifar.cuda()\n",
    "#writer.add_graph(CIFAR10,input)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "outputs": [],
   "source": [
    "#损失函数\n",
    "lose_fuc = nn.CrossEntropyLoss()\n",
    "lose_fuc = lose_fuc.to(device)\n",
    "# if torch.cuda.is_available():\n",
    "#     lose_fuc = lose_fuc.cuda()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "outputs": [],
   "source": [
    "#优化器\n",
    "optimizer = torch.optim.Adam(cifar.parameters(), lr=laring_rate, weight_decay=1e-4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------第 1 轮训练开始-------------------------------------------------------\n",
      "训练次数：100，loss:0.9371758699417114\n",
      "整体测试集上的loss: 0.6826\n",
      "整体测试集上的准确率: 0.7673\n",
      "宏平均精确率: 0.7655\n",
      "宏平均召回率: 0.7673\n",
      "宏平均F1值: 0.7654\n",
      "模型已保存\n",
      "---------------------------------------------第 2 轮训练开始-------------------------------------------------------\n",
      "训练次数：200，loss:0.8451423645019531\n",
      "训练次数：300，loss:0.7438347935676575\n",
      "整体测试集上的loss: 0.6777\n",
      "整体测试集上的准确率: 0.7700\n",
      "宏平均精确率: 0.7675\n",
      "宏平均召回率: 0.7700\n",
      "宏平均F1值: 0.7680\n",
      "模型已保存\n",
      "---------------------------------------------第 3 轮训练开始-------------------------------------------------------\n",
      "训练次数：400，loss:0.81822270154953\n",
      "训练次数：500，loss:0.782566249370575\n",
      "整体测试集上的loss: 0.6789\n",
      "整体测试集上的准确率: 0.7686\n",
      "宏平均精确率: 0.7655\n",
      "宏平均召回率: 0.7686\n",
      "宏平均F1值: 0.7663\n",
      "模型已保存\n",
      "---------------------------------------------第 4 轮训练开始-------------------------------------------------------\n",
      "训练次数：600，loss:0.5952942371368408\n",
      "训练次数：700，loss:0.6876346468925476\n",
      "整体测试集上的loss: 0.6735\n",
      "整体测试集上的准确率: 0.7720\n",
      "宏平均精确率: 0.7690\n",
      "宏平均召回率: 0.7720\n",
      "宏平均F1值: 0.7699\n",
      "模型已保存\n",
      "---------------------------------------------第 5 轮训练开始-------------------------------------------------------\n",
      "训练次数：800，loss:0.7827880382537842\n",
      "训练次数：900，loss:0.608032763004303\n",
      "整体测试集上的loss: 0.6645\n",
      "整体测试集上的准确率: 0.7740\n",
      "宏平均精确率: 0.7723\n",
      "宏平均召回率: 0.7741\n",
      "宏平均F1值: 0.7725\n",
      "模型已保存\n",
      "---------------------------------------------第 6 轮训练开始-------------------------------------------------------\n",
      "训练次数：1000，loss:0.7837024927139282\n",
      "训练次数：1100，loss:0.7735683917999268\n",
      "整体测试集上的loss: 0.6701\n",
      "整体测试集上的准确率: 0.7728\n",
      "宏平均精确率: 0.7711\n",
      "宏平均召回率: 0.7728\n",
      "宏平均F1值: 0.7715\n",
      "模型已保存\n",
      "---------------------------------------------第 7 轮训练开始-------------------------------------------------------\n",
      "训练次数：1200，loss:0.7235760688781738\n",
      "训练次数：1300，loss:0.6962812542915344\n",
      "整体测试集上的loss: 0.6711\n",
      "整体测试集上的准确率: 0.7716\n",
      "宏平均精确率: 0.7692\n",
      "宏平均召回率: 0.7716\n",
      "宏平均F1值: 0.7698\n",
      "模型已保存\n",
      "---------------------------------------------第 8 轮训练开始-------------------------------------------------------\n",
      "训练次数：1400，loss:0.6420724987983704\n",
      "训练次数：1500，loss:0.7306328415870667\n",
      "整体测试集上的loss: 0.6722\n",
      "整体测试集上的准确率: 0.7711\n",
      "宏平均精确率: 0.7685\n",
      "宏平均召回率: 0.7711\n",
      "宏平均F1值: 0.7691\n",
      "模型已保存\n",
      "---------------------------------------------第 9 轮训练开始-------------------------------------------------------\n",
      "训练次数：1600，loss:0.7152178287506104\n",
      "训练次数：1700，loss:0.6252900958061218\n",
      "整体测试集上的loss: 0.6677\n",
      "整体测试集上的准确率: 0.7736\n",
      "宏平均精确率: 0.7715\n",
      "宏平均召回率: 0.7736\n",
      "宏平均F1值: 0.7719\n",
      "模型已保存\n",
      "---------------------------------------------第 10 轮训练开始-------------------------------------------------------\n",
      "训练次数：1800，loss:0.6597272753715515\n",
      "训练次数：1900，loss:0.81855708360672\n",
      "整体测试集上的loss: 0.6695\n",
      "整体测试集上的准确率: 0.7760\n",
      "宏平均精确率: 0.7735\n",
      "宏平均召回率: 0.7760\n",
      "宏平均F1值: 0.7740\n",
      "模型已保存\n",
      "---------------------------------------------第 11 轮训练开始-------------------------------------------------------\n",
      "训练次数：2000，loss:0.778469443321228\n",
      "训练次数：2100，loss:0.6904293894767761\n",
      "整体测试集上的loss: 0.6676\n",
      "整体测试集上的准确率: 0.7726\n",
      "宏平均精确率: 0.7703\n",
      "宏平均召回率: 0.7726\n",
      "宏平均F1值: 0.7709\n",
      "模型已保存\n",
      "---------------------------------------------第 12 轮训练开始-------------------------------------------------------\n",
      "训练次数：2200，loss:0.7555039525032043\n",
      "训练次数：2300，loss:0.6945589184761047\n",
      "整体测试集上的loss: 0.6617\n",
      "整体测试集上的准确率: 0.7741\n",
      "宏平均精确率: 0.7723\n",
      "宏平均召回率: 0.7742\n",
      "宏平均F1值: 0.7727\n",
      "模型已保存\n",
      "---------------------------------------------第 13 轮训练开始-------------------------------------------------------\n",
      "训练次数：2400，loss:0.7379629611968994\n",
      "训练次数：2500，loss:0.8122056126594543\n",
      "整体测试集上的loss: 0.6679\n",
      "整体测试集上的准确率: 0.7726\n",
      "宏平均精确率: 0.7713\n",
      "宏平均召回率: 0.7727\n",
      "宏平均F1值: 0.7715\n",
      "模型已保存\n",
      "---------------------------------------------第 14 轮训练开始-------------------------------------------------------\n",
      "训练次数：2600，loss:0.672622799873352\n",
      "训练次数：2700，loss:0.6619020700454712\n",
      "整体测试集上的loss: 0.6663\n",
      "整体测试集上的准确率: 0.7735\n",
      "宏平均精确率: 0.7707\n",
      "宏平均召回率: 0.7736\n",
      "宏平均F1值: 0.7715\n",
      "模型已保存\n",
      "---------------------------------------------第 15 轮训练开始-------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_4500\\2426641725.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      6\u001B[0m     \u001B[0mcifar\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"---------------------------------------------第 {} 轮训练开始-------------------------------------------------------\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 8\u001B[1;33m     \u001B[1;32mfor\u001B[0m \u001B[0mdata\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtrain_dataloader\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      9\u001B[0m         \u001B[0mimgs\u001B[0m \u001B[1;33m,\u001B[0m \u001B[0mtag\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m         \u001B[0mimgs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mimgs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Program Files (x86)\\Anaconda\\envs\\DeepLearning\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    528\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sampler_iter\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    529\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_reset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 530\u001B[1;33m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    531\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    532\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mIterable\u001B[0m \u001B[1;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Program Files (x86)\\Anaconda\\envs\\DeepLearning\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    568\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_next_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    569\u001B[0m         \u001B[0mindex\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_next_index\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# may raise StopIteration\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 570\u001B[1;33m         \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dataset_fetcher\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfetch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# may raise StopIteration\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    571\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_pin_memory\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    572\u001B[0m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_utils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Program Files (x86)\\Anaconda\\envs\\DeepLearning\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001B[0m in \u001B[0;36mfetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     47\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mfetch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     48\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mauto_collation\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 49\u001B[1;33m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0midx\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     50\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     51\u001B[0m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Program Files (x86)\\Anaconda\\envs\\DeepLearning\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     47\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mfetch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     48\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mauto_collation\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 49\u001B[1;33m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0midx\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     50\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     51\u001B[0m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Program Files (x86)\\Anaconda\\envs\\DeepLearning\\lib\\site-packages\\torchvision\\datasets\\cifar.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m    116\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    117\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 118\u001B[1;33m             \u001B[0mimg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    119\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    120\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtarget_transform\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Program Files (x86)\\Anaconda\\envs\\DeepLearning\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, img)\u001B[0m\n\u001B[0;32m     93\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mimg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     94\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mt\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransforms\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 95\u001B[1;33m             \u001B[0mimg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     96\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mimg\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     97\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Program Files (x86)\\Anaconda\\envs\\DeepLearning\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, pic)\u001B[0m\n\u001B[0;32m    133\u001B[0m             \u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mConverted\u001B[0m \u001B[0mimage\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    134\u001B[0m         \"\"\"\n\u001B[1;32m--> 135\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_tensor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpic\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    136\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    137\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__repr__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Program Files (x86)\\Anaconda\\envs\\DeepLearning\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001B[0m in \u001B[0;36mto_tensor\u001B[1;34m(pic)\u001B[0m\n\u001B[0;32m    149\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mpic\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmode\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"1\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    150\u001B[0m         \u001B[0mimg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m255\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mimg\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 151\u001B[1;33m     \u001B[0mimg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mimg\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mview\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpic\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msize\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpic\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msize\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpic\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgetbands\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    152\u001B[0m     \u001B[1;31m# put it from HWC to CHW format\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    153\u001B[0m     \u001B[0mimg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mimg\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpermute\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcontiguous\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "total_train_step = 0\n",
    "total_test_step = 0\n",
    "class_names = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "for i in range(epoch):\n",
    "    cifar.train()\n",
    "    print(\"---------------------------------------------第 {} 轮训练开始-------------------------------------------------------\".format(i+1))\n",
    "    for data in train_dataloader:\n",
    "        imgs , tag = data\n",
    "        imgs = imgs.to(device)\n",
    "        tag = tag.to(device)\n",
    "        # if torch.cuda.is_available():\n",
    "        #     imgs = imgs.cuda()\n",
    "        #     tag = tag.cuda()\n",
    "        outputs = cifar(imgs)\n",
    "        lose = lose_fuc( outputs , tag)\n",
    "\n",
    "        #开始反向传播，进行梯度下降\n",
    "        optimizer.zero_grad()\n",
    "        lose.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_step += 1\n",
    "        if total_train_step % 100 == 0:\n",
    "            print(\"训练次数：{}，loss:{}\".format(total_train_step,lose))\n",
    "            writer.add_scalar(\"train_lose\",lose,total_train_step)\n",
    "\n",
    "    # 测试步骤开始\n",
    "    cifar.eval()\n",
    "    total_test_lose = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    the_best_accuaray = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:\n",
    "            imgs, tags = data\n",
    "            imgs = imgs.to(device)\n",
    "            tags = tags.to(device)\n",
    "\n",
    "            outputs = cifar(imgs)\n",
    "            lose = lose_fuc(outputs, tags)\n",
    "            total_test_lose += lose.item()\n",
    "\n",
    "            # 收集预测和真实标签\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())#将所有的预测值都加入all_preds列表中\n",
    "            all_targets.extend(tags.cpu().numpy())#将所有的真实值都加入all_targetss列表中\n",
    "\n",
    "    # 转换为numpy数组\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_targets = np.array(all_targets)\n",
    "\n",
    "    # 计算整体准确率\n",
    "    accuracy = (all_preds == all_targets).mean()\n",
    "\n",
    "    # 计算每个类别的精确率、召回率和F1值\n",
    "    try:\n",
    "        # 尝试使用新版本的参数\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            all_targets, all_preds, average=None, zero_division=0\n",
    "        )\n",
    "    except TypeError:\n",
    "        # 如果出现错误，使用旧版本兼容方式\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            all_targets, all_preds, average=None\n",
    "        )\n",
    "        # 手动处理除零错误\n",
    "        precision = np.nan_to_num(precision, nan=0.0)\n",
    "        recall = np.nan_to_num(recall, nan=0.0)\n",
    "        f1 = np.nan_to_num(f1, nan=0.0)\n",
    "\n",
    "    # 计算宏平均（macro-average）指标\n",
    "    macro_precision = np.mean(precision)\n",
    "    macro_recall = np.mean(recall)\n",
    "    macro_f1 = np.mean(f1)\n",
    "\n",
    "    # 打印结果\n",
    "    print(f\"整体测试集上的loss: {total_test_lose / len(test_dataloader):.4f}\")\n",
    "    print(f\"整体测试集上的准确率: {accuracy:.4f}\")\n",
    "    print(f\"宏平均精确率: {macro_precision:.4f}\")\n",
    "    print(f\"宏平均召回率: {macro_recall:.4f}\")\n",
    "    print(f\"宏平均F1值: {macro_f1:.4f}\")\n",
    "\n",
    "    # 记录到TensorBoard\n",
    "    writer.add_scalar(\"test_loss\", total_test_lose / len(test_dataloader), total_test_step)\n",
    "    writer.add_scalar(\"test_accuracy\", accuracy, total_test_step)\n",
    "    writer.add_scalar(\"test_precision\", macro_precision, total_test_step)\n",
    "    writer.add_scalar(\"test_recall\", macro_recall, total_test_step)\n",
    "    writer.add_scalar(\"test_f1\", macro_f1, total_test_step)\n",
    "\n",
    "    # 记录每个类别的指标\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        writer.add_scalar(f\"class_{class_name}/precision\", precision[i], total_test_step)\n",
    "        writer.add_scalar(f\"class_{class_name}/recall\", recall[i], total_test_step)\n",
    "        writer.add_scalar(f\"class_{class_name}/f1\", f1[i], total_test_step)\n",
    "\n",
    "    total_test_step += 1\n",
    "    if accuracy > the_best_accuaray:\n",
    "        torch.save(cifar.state_dict(), \"best_cifar10.pth\")\n",
    "        the_best_accuaray = accuracy\n",
    "    torch.save(cifar.state_dict(), \"last_cifar10.pth\")\n",
    "    print(\"模型已保存\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=137x147 at 0x19C807910C8>\n",
      "tensor([[[0.5961, 0.6353, 0.6627,  ..., 0.5216, 0.5255, 0.5137],\n",
      "         [0.5490, 0.5765, 0.6078,  ..., 0.4902, 0.4902, 0.4784],\n",
      "         [0.4784, 0.4784, 0.4863,  ..., 0.4902, 0.4784, 0.4627],\n",
      "         ...,\n",
      "         [0.2902, 0.3255, 0.2588,  ..., 0.3608, 0.3255, 0.3529],\n",
      "         [0.2941, 0.3294, 0.4471,  ..., 0.3804, 0.2824, 0.2980],\n",
      "         [0.3098, 0.4745, 0.8157,  ..., 0.4275, 0.3451, 0.3686]],\n",
      "\n",
      "        [[0.5647, 0.6118, 0.6392,  ..., 0.6784, 0.6784, 0.6745],\n",
      "         [0.5294, 0.5608, 0.5922,  ..., 0.6549, 0.6549, 0.6471],\n",
      "         [0.5686, 0.5725, 0.5843,  ..., 0.6510, 0.6471, 0.6392],\n",
      "         ...,\n",
      "         [0.4745, 0.5020, 0.4196,  ..., 0.5176, 0.4824, 0.5294],\n",
      "         [0.4706, 0.4902, 0.5608,  ..., 0.5373, 0.4314, 0.4667],\n",
      "         [0.4588, 0.5765, 0.8510,  ..., 0.5961, 0.5137, 0.5451]],\n",
      "\n",
      "        [[0.4863, 0.5373, 0.5647,  ..., 0.3490, 0.3373, 0.3333],\n",
      "         [0.4549, 0.4824, 0.5176,  ..., 0.3020, 0.3020, 0.2980],\n",
      "         [0.3647, 0.3569, 0.3686,  ..., 0.2980, 0.2902, 0.2784],\n",
      "         ...,\n",
      "         [0.1922, 0.2314, 0.1882,  ..., 0.2275, 0.2118, 0.1922],\n",
      "         [0.2000, 0.2275, 0.3804,  ..., 0.2314, 0.1804, 0.1569],\n",
      "         [0.2157, 0.3961, 0.7922,  ..., 0.2510, 0.2078, 0.2275]]])\n",
      "tensor([[-4.1064, -3.4982,  3.4102,  1.5949, -1.7137,  4.5600, -0.2615, -0.8493,\n",
      "         -4.1946, -3.3213]])\n",
      "dog\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img_path = \"./image/test/dog5.png\"\n",
    "img = Image.open(img_path)\n",
    "img = img.convert('RGB')\n",
    "print(img)\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((32,32)),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "img = transform(img)\n",
    "print(img)\n",
    "\n",
    "model = CIFAR10()\n",
    "model.load_state_dict(torch.load(\"best_cifar10.pth\"))\n",
    "\n",
    "img = torch.reshape(img,(1,3,32,32))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(img)\n",
    "print(output)\n",
    "result_list = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "print(result_list[output.argmax(1)])"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
